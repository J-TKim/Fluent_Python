{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트와 바이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 문자 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬 3 str에서는 항상 유니코드 문자 항목으로 가져온다\n",
    "\n",
    "- 유니코드 표준에서 'U+' 접두사를 붙혀 4자리에서 6자리 사이의 16진수로 표현한다\n",
    "- 문자를 표현하는 실제 바이트는 사용하는 인코딩에 따라 달라진다 인코딩은 코드 포인트를 바이트 시퀀스로 변환하는 알고리즘이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "b'caf\\xc3\\xa9'\n",
      "5\n",
      "café\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-1 인코딩과 디코딩\n",
    "s = 'café'\n",
    "print(len(s)) # s는 4개의 유니코드 문자를 갖고있다\n",
    "\n",
    "b = s.encode('utf-8') # UTF-8을 이용해서 str을 bytes로 인코딩한다\n",
    "print(b) # byters 리터럴은 접두사 b로 시작한다\n",
    "print(len(b)) # bytes 형인 b는 다섯 바이트로 구성된다. é가 UTF-8에서 두 바이트로 인코딩된다\n",
    "\n",
    "print(b.decode('utf-8')) # UTF-8 인코딩을 이용해서 bytes를 str로 디코딩한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 바이트에 대한 기본 지식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'caf\\xc3\\xa9'\n",
      "99\n",
      "b'c'\n",
      "bytearray(b'caf\\xc3\\xa9')\n",
      "bytearray(b'\\xa9')\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-2 bytes와 byearray로 지정한 5바이트 시퀀스\n",
    "cafe = bytes('café', encoding='utf-8') # bytes는 str에 인코딩을 지정해서 만들 수 있다\n",
    "print(cafe)\n",
    "print(cafe[0]) # c가 ASCII코드 기준 99이다\n",
    "print(cafe[:1]) # bytes는 슬라이싱 해도 bytes이다\n",
    "cafe_arr = bytearray(cafe)\n",
    "print(cafe_arr) # bytearray에 대한 리터럴 구문은 없다. bytes를 리터럴 인수로 사용해서 bytearray()를 표현한다\n",
    "print(cafe_arr[-1:]) # bytearray는 슬라이싱해도 bytearray이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__byte_type[0] != byte_type[:1] 인 사실을 명심하자 str의 경우에만 s[0] == s[:1] 이 성립한다__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이진 시퀀스는 바이트 값에 따라 다음 형태로 출력한다\n",
    "- 화면에 출력 가능한 아스키 문자는 (' ' 부터 '~')는 아스키 문자 그대로 출력한다\n",
    "- 탭, 개행 문자, 캐리지 리턴, 백슬래시는 (\\t, \\n, \\r, \\\\)로 출력한다\n",
    "- 그 외의 값은 널 바이트를 나타내는 \\x00처럼 16진수 이스케이프 시퀀스로 출력한다\n",
    "\n",
    "그렇기 때문에 café가 b'caf\\xc3\\xa9'가 된 것이다. (caf는 아스키코드로 표현 가능, é는 불가하기 때문에 이스케이프 시퀀스로 포현)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bytes와 bytes는 포매팅하는 format()과 format_map()을 메서드를 제외하고는 str이 제공하는 모든 메서드를 지원하고, 추가로 유니코드 데이터 관련 메서드 역시 지원한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1K\\xce\\xa9'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fromhex()라는 str에는 없는 클래스 메서드 (공백으로 구분된 16진수 쌍을 파싱해서 이진 시퀀스를 만들 수 있다)\n",
    "bytes.fromhex('31 4B CE A9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 4-3 배열의 원시 데이터에서 bytes 초기화하기\n",
    "import array\n",
    "\n",
    "numbers = array.array('h', [-2, -1, 0, 1, 2]) # 'h'타입코드는 short int(16비트) 형의 배열을 생성한다\n",
    "octets = bytes(numbers) # octets는 number를 구성하는 바이트들의 사본을 가지고있다\n",
    "octets # 다섯개의 shor int 형을 나타내는 10 바이트이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 구조체와 메모리 뷰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'GIF89a5\\x05\\xee\\x02'\n",
      "(b'GIF', b'89a', 1333, 750)\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-4 memoryview와 struct를 사용해서 GIF 이미지 헤더 조사하기\n",
    "import struct\n",
    "fmt = '<3s3sHH' # struct 포맷을 지정한다 <: 리틀엔디언, 3s3s는 3바이트 시퀀스 두 개, HH는 16비트 정수 두 개를 나타낸다\n",
    "with open('test.gif', 'rb') as fp:\n",
    "    img = memoryview(fp.read()) # 메모리에 로딩된 파일 내용으로부터 memoryview를 생성한다\n",
    "\n",
    "header = img[:10] # 먼저 생성한 memoryview를 슬라이싱해서 새로운 memeoryview를 만든다. 이 때 아무런 바이트도 복사하지 않는다\n",
    "print(bytes(header)) # 화면에 출력하기 위해 bytes로 변환한다. 이 때 10 바이트가 복사된다\n",
    "print(struct.unpack(fmt, header)) # memoryview를 튜플로 언패킹한다 (종류, 버전, 너비 높이)\n",
    "del header # 객체에 연결된 메모리를 해제하기 위해 참조를 삭제한다\n",
    "del img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 기본 인코더/디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin_1\tb'El Ni\\xf1o'\n",
      "utf_8\tb'El Ni\\xc3\\xb1o'\n",
      "utf_16\tb'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-5 전혀 다른 바이트 시퀀스를 만든느 세 개의 코덱으로 인코딩한 El Niño 문자열\n",
    "for codec in ['latin_1', 'utf_8', 'utf_16']:\n",
    "    print(codec, 'El Niño'.encode(codec), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 인코딩/디코딩 문제 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 UnicodeEncodeError 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf_8\tb'S\\xc3\\xa3o Paulo'\n",
      "utf_16\tb'\\xff\\xfeS\\x00\\xe3\\x00o\\x00 \\x00P\\x00a\\x00u\\x00l\\x00o\\x00'\n",
      "iso8859_1\tb'S\\xe3o Paulo'\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character 'ã' in position 1: character maps to <undefined>\n",
      "b'So Paulo'\n",
      "b'S?o Paulo'\n",
      "b'S&#227;o Paulo'\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-6 바이트로 인코딩하기: 성공 및 에러 처리\n",
    "city = 'São Paulo'\n",
    "\n",
    "\"\"\"\n",
    "utf_? 계열 인코딩은 모든 str을 처리할 수 있다\n",
    "iso8859_1도 São Paulo 문자열을 처리할 수 있다\n",
    "\"\"\"\n",
    "for codec in ['utf_8', 'utf_16', 'iso8859_1', 'cp437']:\n",
    "    try:\n",
    "        print(f'{codec}\\t{city.encode(codec)}')\n",
    "    except UnicodeEncodeError:\n",
    "        print(\"UnicodeEncodeError: 'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>\") # cp437은 ã를 인코딩 할 수 없다 UnicodeEncodeError 발생시킴\n",
    "\n",
    "print(city.encode('cp437', errors='ignore')) # errors='ignore' 처리기는 인코딩 할 수 없는 문자를 건너뛴다\n",
    "print(city.encode('cp437', errors='replace')) # 'replace' 처리기는 인코딩 할 수 없는 문자를 ?로 치환한다\n",
    "print(city.encode('cp437', errors='xmlcharrefreplace')) # xmlcharrefreplace 처리기는 인코딩할 수 없는 문자를 XML 개체로 치환한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 UnicodeDecodeError 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montréal\n",
      "Montrιal\n",
      "MontrИal\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte\n",
      "Montr�al\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-7 str에서 bytes로 디코딩하기: 성공 및 에러 처리\n",
    "octets = b'Montr\\xe9al' # latin1로 인코딩된 Montréal이다. \\xe9는 é를 나타내는 바이트\n",
    "print(octets.decode('cp1252')) # 'cp1252'는 latin1의 슈퍼셋이므로 제대로 디코딩 된다\n",
    "print(octets.decode('iso8859_7')) # ISO-8859-7은 그리스어를 위한 코덱이므로 엉뚱하게 해석한다 (에러는 x)\n",
    "print(octets.decode('koi8_r')) # KOI8-R은 러시아어를 위한 코덱이여서 И으로 해석\n",
    "\n",
    "try:\n",
    "    print(octets.decode('utf_8')) # 'utf_8' 코덱으로는 변환할 수 없기 때문에 UnicodeDecodeError 발생\n",
    "except UnicodeDecodeError:\n",
    "    print(\"UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte\")\n",
    "\n",
    "print(octets.decode('utf-8', errors='replace')) # 'replace' 처리기를 사용하여 �로 치환한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 예상과 달리 인코딩된 모듈을 로딩할 때 발생하는 SyntaxError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá, mundo!\n"
     ]
    }
   ],
   "source": [
    "# coding: cp1252\n",
    "# 예제 4-8 ola.py: 'Hello, World!'포르투갈 버전\n",
    "\n",
    "print('Olá, mundo!') # 파일 꼭대기에 # coding: cp1252 주석을 달아 SyntaxError를 해결할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 방식의 비아스키 식별자도 사용이 가능하지만 모든 사람이 알아볼 수 있도록 영문 식별자를 사용하는것이 좋다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ação = 'PBR' # ação = stock\n",
    "Ɛ = 10**-6 # Ɛ = epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4 바이트 시퀀스의 인코딩 방식을 알아내는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chardet 패키지를 사용하면 인코딩 방식을 유추해낼 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zen.txt: ascii with confidence 1.0\r\n"
     ]
    }
   ],
   "source": [
    "!chardetect zen.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.5 BOM: 유용한 깨진 문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u16 = 'El Niño'.encode('utf_16')\n",
    "u16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b'\\xff\\xfe' 문자가 앞에 나와있다. 이 문자가 바로 BOM(바이트 순서 표시)로 인코뎅한 인텔 CPU의 리틀엔디언 바이트 순서를 나타낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 포인트가 U+0045 (십진수 69)인 'E'문자는 다음과 같이 69와 0으로 인코딩되었다(list(u16)[2:4]) (빅엔디언 컴퓨터에서는 인코딩 순서가 반대가되어 0과 69로 인코딩된다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[255, 254, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(u16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTF-16 인코딩은 특수문자를 텍스트 앞에 붙힌다. 해당 문자는 b'\\xff\\xfe'로 인코딩되며 UTF-16에 U+FFFE에 해당하는 문자가 없으므로 b'\\xff\\xfe' 문자는 출력되지 않는다 (ZERO WIDTH NO-BREAK SPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTF-16과 다르게 리틀엔디언을 명시하는 UTF-16LE와 빅엔디언을 명시하는 UTF-16BE로 변형하면, BOM을 생성하지 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]\n",
      "[0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111]\n"
     ]
    }
   ],
   "source": [
    "u16le = 'El Niño'.encode('utf_16le')\n",
    "print(list(u16le))\n",
    "\n",
    "u16be = 'El Niño'.encode('utf_16be')\n",
    "print(list(u16be))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 텍스트 파일 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 4-9 플랫폼 인코딩 문제 (지금 실습을 진행하는 pc가 우분투여서 그런지 버그가 발생하지 않음)\n",
    "open('cafe.txt', 'w', encoding='utf_8').write('café')\n",
    "open('cafe.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='cafe.txt' mode='w' encoding='utf_8'>\n",
      "4\n",
      "5\n",
      "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='cp1252'>\n",
      "cp1252\n",
      "cafÃ©\n",
      "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='utf_8'>\n",
      "café\n",
      "<_io.BufferedReader name='cafe.txt'>\n",
      "b'caf\\xc3\\xa9'\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-10 [예제 4-9]를 윈도우에서 실행해서 조사하면 버그와 해결 방법을 찾을 수 있다\n",
    "fp = open('cafe.txt', 'w', encoding='utf_8')\n",
    "print(fp) # open()함수는 텍스트 모드로 작동하며 TextIOWrapper 객체를 반환\n",
    "print(fp.write('café')) # 지정한 문자의 유니코드 문자 수를 반환\n",
    "fp.close()\n",
    "\n",
    "import os\n",
    "print(os.stat('cafe.txt').st_size) # 파일이 5 바이트라고 알려준다 (é가 2바이트)\n",
    "fp2 = open('cafe.txt', encoding='cp1252')\n",
    "print(fp2) # 내 환경에서는 UTF-8로 인코딩됨 => 실습을 위해 'cp1252'지정\n",
    "print(fp2.encoding)\n",
    "print(fp2.read()) # é가 제대로 해석되지 않음\n",
    "\n",
    "fp3 = open('cafe.txt', encoding='utf_8') # 올바른 인코딩으로 연다\n",
    "print(fp3)\n",
    "print(fp3.read()) # 올바르게 해석\n",
    "\n",
    "fp4 = open('cafe.txt', 'rb') # 'rb' 플래그는 파일으 이진 모드로 읽도록 한다\n",
    "print(fp4)\n",
    "print(fp4.read()) # 이 파일을 열면 bytes가 반환된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 기본 인코딩 설정: 정신 나간거 아냐?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내 실습환경은 ubuntu 이다 window의 경우에는 기본적으로 'cp1252'으로 인코딩 할 것이다\n",
    "\n",
    "기존 인코딩에 의존하지 않도록 조심하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> 'UTF-8'\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> 'UTF-8'\n",
      "           sys.stdout.isatty() -> False\n",
      "           sys.stdout.encoding -> 'UTF-8'\n",
      "            sys.stdin.isatty() -> False\n",
      "            sys.stdin.encoding -> 'UTF-8'\n",
      "           sys.stderr.isatty() -> False\n",
      "           sys.stderr.encoding -> 'UTF-8'\n",
      "      sys.getdefaultencoding() -> 'utf-8'\n",
      "   sys.getfilesystemencoding() -> 'utf-8'\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-11 인코딩 기본값 알아보기\n",
    "import sys, locale\n",
    "\n",
    "expressions = \"\"\"\n",
    "        locale.getpreferredencoding()\n",
    "        type(my_file)\n",
    "        my_file.encoding\n",
    "        sys.stdout.isatty()\n",
    "        sys.stdout.encoding\n",
    "        sys.stdin.isatty()\n",
    "        sys.stdin.encoding\n",
    "        sys.stderr.isatty()\n",
    "        sys.stderr.encoding\n",
    "        sys.getdefaultencoding()\n",
    "        sys.getfilesystemencoding()\n",
    "\"\"\"\n",
    "\n",
    "my_file = open('cafe.txt', 'w')\n",
    "\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)\n",
    "    print(expression.rjust(30), '->', repr(value)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 제대로 비교하기 위해 유니코드 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "café café\n",
      "4 5\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# café'를 네 개나 다섯 개의 코드 포인트를 이용해 두가지 방식으로 표현한 코드\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "print(s1, s2)\n",
    "print(len(s1), len(s2))\n",
    "print(s1 == s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U+0301이 COMBINING ACUTE ACCENT이기 때문에 e뒤에 이 문자가 오면 é를 만든다 고로 s1 == s2 는 True가 나와야하는데 그렇지 않다.   \n",
    "위 문제는 unicodedata.normalize()함수를 사용해 해결할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5\n",
      "4 4\n",
      "5 5\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "print(len(s1), len(s2))\n",
    "print(len(normalize('NFC', s1)), len(normalize('NFC', s2))) # NFC: 코드 포인트를 조합해 가장 짧은 동일 문자열을 생성\n",
    "print(len(normalize('NFD', s1)), len(normalize('NFD', s2))) # NFD: 조합된 문자를 기존 문자와 별도의 결합 문자로 분리\n",
    "print(normalize('NFC', s1) == normalize('NFC', s2))\n",
    "print(normalize('NFD', s1) == normalize('NFD', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHM SIGN\n",
      "GREEK CAPITAL LETTER OMEGA\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# NFC로 정규화 할 때 전기 저항을 나타내는 옴은, 그리스어 대문자 오메가로 정규화\n",
    "from unicodedata import normalize, name\n",
    "ohm = '\\u2126'\n",
    "print(name(ohm))\n",
    "ohm_c = normalize('NFC', ohm)\n",
    "print(name(ohm_c))\n",
    "print(ohm == ohm_c)\n",
    "print(normalize('NFC', ohm) == normalize('NFC', ohm_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1⁄2\n",
      "42\n",
      "µ μ\n",
      "181 956\n",
      "'MICRO SIGN' 'GREEK SMALL LETTER MU'\n"
     ]
    }
   ],
   "source": [
    "# NFKC의 호환성 분할\n",
    "from unicodedata import normalize, name\n",
    "half = '½'\n",
    "print(normalize('NFKC', half)) # '½'을 1/2로 치환\n",
    "\n",
    "four_squared='42'\n",
    "print(normalize('NFKC', four_squared))\n",
    "\n",
    "micro = 'µ' # micro사인을 mu로 치환\n",
    "micro_kc = normalize('NFKC', micro)\n",
    "print(micro, micro_kc)\n",
    "print(ord(micro), ord(micro_kc))\n",
    "print(repr(name(micro)), repr(name(micro_kc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.1 케이스 폴딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 텍스트를 소문자로 변환하는 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICRO SIGN\n",
      "GREEK SMALL LETTER MU\n",
      "µ μ\n",
      "LATIN SMALL LETTER SHARP S\n",
      "ß ss\n"
     ]
    }
   ],
   "source": [
    "micro = 'µ'\n",
    "print(name(micro))\n",
    "micro_cf = micro.casefold()\n",
    "print(name(micro_cf)) # casefold() 케이스 폴딩 메서드를 이용하면 마이크로 기호를 뮤로 변환\n",
    "print(micro, micro_cf)\n",
    "eszett = 'ß'\n",
    "print(name(eszett))\n",
    "eszett_cf = eszett.casefold()\n",
    "print(eszett, eszett_cf) # 'ß' 에스제트 문자를 ss로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.2 정규화된 텍스트 매칭을 위한 유틸리티 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NFC는 대부분의 애플리케이션에서 사용할 수 있는 최고의 정규화된 형태이고, str.casefold()는 대소문자 구분 없이 문자를 비교할 때 가장 좋은 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-13 normeq.py: 정규화된 유니코드 문자열 비교\n",
    "\n",
    "from unicodedata import normalize\n",
    "\n",
    "def nfc_equal(str1, str2):\n",
    "    return normalize('NFC', str1) == normalize('NFC', str2)\n",
    "\n",
    "def fold_equal(str1, str2):\n",
    "    return (normalize('NFC', str1).casefold() ==\n",
    "            normalize('NFC', str2).casefold())\n",
    "\n",
    "\n",
    "#정규화된 유니코드 문자열을 비교하기 위한 유틸리티 함수\n",
    "\n",
    "# 대소문자를 구분하고, NFC를 사용하는 경우\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "print(s1 == s2) # F\n",
    "print(nfc_equal(s1, s2)) # T\n",
    "print(nfc_equal('A', 'a')) # F\n",
    "\n",
    "# 케이스 폴딩과 함께 NFC를 사용하는 경우\n",
    "s3 = 'Straße'\n",
    "s4 = 'strasse'\n",
    "print(s3 == s4) # F\n",
    "print(nfc_equal(s3, s4)) # F\n",
    "print(fold_equal(s3, s4)) # T\n",
    "print(fold_equal(s1, s2)) # T\n",
    "print(fold_equal('A', 'a')) # T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.3 극단적인 '정규화': 발음 구별 기호 제거하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구글 검색에서 문맥에 따라 악센트나 갈고리형 기호 들의 발음 구별기호를 무시하는 방법을 사용하곤 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-14 결합 표시를 모두 제거하는 함수(sanitize.py 모듈)\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"발음 구별 기호를 모두 제거한다.\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt) # 모든 문자를 기본 문자와 결합 표시로 분해한다\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c)) # 결합 표시를 모두 걸러낸다\n",
    "    return unicodedata.normalize('NFC', shaved) # 문자를 모두 재결합 시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”\n",
      "Ζεφυρος, Zefiro\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-15 [예제 4-14]의 shave_masks()를 사용하는 두 가지 예제\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "print(shave_marks(order)) # è ç í 만 대체되었다\n",
    "Greek = 'Ζέφυρος, Zéfiro'\n",
    "print(shave_marks(Greek)) # έ é 만 대체되었다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shave_marks()는 라틴 텍스트를 순수한 아스키코드로 변한하기 위한 것 인데, 단지 악센트만 제거해서 아스키 문자로 만들 수 없는 그리스 문자도 변경한다.   \n",
    "따라서 [예제 4-16]과 같이 모든 기반 문자를 분석해서 기반 문자가 라틴 알파벳인 경우에만 연결된 표시를 제거하는 방법이 더 좋다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-16 라틴 문자에서 결합 표시 기호를 제거하는 함수\n",
    "def shave_marks_latin(txt):\n",
    "    \"\"\"라틴 기반 문자에서 발음 구별 기호를 모두 제거한다\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt) # 모든 문자를 기반 문자와 결합 표시 기호로 분리한다\n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base: # 기반 문자가 라틴 문자일 때 결합 표시 기호를 건너뛴다\n",
    "            continue # 라틴 기반 문자의 발음 구별 기호를 무시한다\n",
    "        keepers.append(c) # 아니면 현재 문자를 보관한다\n",
    "        # 결합 문자가 아니라면, 이 문자를 새로운 기반 문자로 간주한다\n",
    "        if not unicodedata.combining(c): # 새로운 기반 문자를 찾아내고 라틴 문자인지 판단한다\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved) # 문자들을 모두 결합하고 NFC 방식으로 정규화한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원형 따움표, 전각 대시, 작은 점 등 서양 텍스트에서 널리 사용되는 기호들을 아스키에 해당하는 문자로 바꾸는 훨씬 더 극단적인 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-17 서양 활자(타이포그래픽) 기호를 아스키로 변환하기\n",
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—˜›\"\"\", # 문자 대 문자 치환을 위한 매핑 태이블을 만든다\n",
    "                            \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    " \n",
    "multi_map = str.maketrans({ # 문자 대 문자열 치환을 위한 매핑 테이블을 만든다\n",
    "    '€': '<euro>',\n",
    "    '…': '...',\n",
    "    'Œ': 'OE',\n",
    "    '™': '(TM)',\n",
    "    'œ': 'oe',\n",
    "    '‰': '<per mille>',\n",
    "    '‡': '**',\n",
    "}) \n",
    " \n",
    "multi_map.update(single_map) # 매핑 테이블을 병합\n",
    "\n",
    "def dewinize(txt):\n",
    "    \"\"\"Win1252 기호를 아스키 문자나 시퀀스로 치환한다\"\"\"\n",
    "    return txt.translate(multi_map) # dewinize() 함수는 아스키나 latin1 텍스트에 영향을 미치지 않으며, 마소가 cp1252안의 latin1에 추가한 문자들만 변경\n",
    "\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt)) # dewinize()를 호출해 발흠 구별 기호를 제거\n",
    "    no_marks = no_marks.replace('ß', 'ss') # 에스체트를 'ss'로 치환한다 (대소문자 유지를 위해 casefold()사용하지 않음)\n",
    "    return unicodedata.normalize('NFKC', no_marks) # NFKC 정규화를 적용해서 호환성 코드 포인트로 대체된 문자열을 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"\n",
      "\"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-18 [예제 4-17]의 asciize()를 사용하는 두 가지 예제\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "print(dewinize(order)) # 둥근 따움표, 작은점 상표권 기호를 대치\n",
    "print(asciize(order)) # dewinize를 적용하고, 발음 구별 기호를 제거한 후 에스체트를 'ss'로 대치한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 유니코드 텍스트 정렬하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비아스키 문자를 사용하는 경우 정렬이 이상하게 되는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acerola', 'atemoia', 'açaí', 'caju', 'cajá']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cajá는 caja로 처리하여 caju보다 먼저 나와야 올바르다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['açaí', 'acerola', 'atemoia',  'cajá', 'caju'] # 올바르게 정렬된 순서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비아스키 텍스트는 locale.strxfrm()함수를 이용해 변환하는 것이 표준이다.    \n",
    "    \n",
    "locale.strxfrm()함수를 활성화하려면 현지어를 설정하고 OS가 이 설정어를 지원하도록 해야한다.    \n",
    "     \n",
    "다음은 언어가 en_US.UTF-8 로 설정된 우분투16.04에서 locale.strxfrm()함수를 사용한 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_US.UTF-8\n",
      "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-19 locale.strxfrm()함수를 정렬키로 사용하기\n",
    "import locale\n",
    "print(locale.setlocale(locale.LC_COLLATE, ''))\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits, key=locale.strxfrm)\n",
    "print(sorted_fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.1 유니코드 대조 알고리즘을 이용한 정렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유니코드 대조 알고리즘을 파이썬으로 구현한 PyUCA 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 4-20 pyuca.Collator.sort_key() 메서드 사용하기\n",
    "import pyuca # 없으면 pip install pyuca로 설치\n",
    "coll = pyuca.Collator()\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits, key=coll.sort_key)\n",
    "sorted_fruits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 유니코드 데이터베이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+0031\t  1   \tre_dig\tisdig\tisnum\t 1.00\tDIGIT ONE\n",
      "U+00bc\t  ¼   \t-\t-\tisnum\t 0.25\tVULGAR FRACTION ONE QUARTER\n",
      "U+00b2\t  ²   \t-\tisdig\tisnum\t 2.00\tSUPERSCRIPT TWO\n",
      "U+0969\t  ३   \tre_dig\tisdig\tisnum\t 3.00\tDEVANAGARI DIGIT THREE\n",
      "U+136b\t  ፫   \t-\tisdig\tisnum\t 3.00\tETHIOPIC DIGIT THREE\n",
      "U+216b\t  Ⅻ   \t-\t-\tisnum\t12.00\tROMAN NUMERAL TWELVE\n",
      "U+2466\t  ⑦   \t-\tisdig\tisnum\t 7.00\tCIRCLED DIGIT SEVEN\n",
      "U+2480\t  ⒀   \t-\t-\tisnum\t13.00\tPARENTHESIZED NUMBER THIRTEEN\n",
      "U+3285\t  ㊅   \t-\t-\tisnum\t 6.00\tCIRCLED IDEOGRAPH SIX\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-21 유니코드 데이터베이스 수치형 문자 메타데이터 사용 예\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "re_digit = re.compile(r'\\d')\n",
    "\n",
    "sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'\n",
    "\n",
    "for char in sample:\n",
    "    print('U+%04x' % ord(char), # U+0000 포맷의 코드 포이늩\n",
    "         char.center(6), # 길이가 6인 str의 중앙에 놓인 문자\n",
    "         're_dig' if re_digit.match(char) else '-', # r'\\d' 정규 표현식과 일치하면 re_dig 표시\n",
    "         'isdig' if char.isdigit() else '-', # char.isdigit()가 참이면 isdig 표시\n",
    "         'isnum' if char.isnumeric() else '-', # char.isnumeric()이 참이면 isnum 표시\n",
    "         format(unicodedata.numeric(char), '5.2f'), # 전체 너비는 5칸이며 소수점 2자리까지 포맷한 숫자값\n",
    "         unicodedata.name(char), # 유니코드 문자명\n",
    "         sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 이중 모드 str 및 bytes API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9.1 정규 표현식에서의 str과 bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규 표현식을 str, bytes에서 사용할 수 있지만, bytes에 정규 표현식을 사용하면 아스키 범위를 벗어나는 문자들은 숫자나 단어로 처리하지 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "  'Ramanujan saw ௧௭௨௯ as 1729 = 1³ + 12³ = 9³ + 10³.'\n",
      "Numbers\n",
      "  str  : ['௧௭௨௯', '1729', '1', '12', '9', '10']\n",
      "  bytes: [b'1729', b'1', b'12', b'9', b'10']\n",
      "Words\n",
      "  str  : ['Ramanujan', 'saw', '௧௭௨௯', 'as', '1729', '1³', '12³', '9³', '10³']\n",
      "  bytes: [b'Ramanujan', b'saw', b'as', b'1729', b'1', b'12', b'9', b'10']\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-22 ramanujan.py: 간단한 str과 bytes 정규 표현식의 동작 비교\n",
    "import re\n",
    "\n",
    "# 앞의 두 정규 표현식은 str형 이다.\n",
    "re_numbers_str = re.compile(r'\\d+')\n",
    "re_words_str = re.compile(r'\\w+')\n",
    "\n",
    "# 뒤의 두 정규 표현식은 bytes형 이다.\n",
    "re_numbers_bytes = re.compile(rb'\\d+')\n",
    "re_words_bytes = re.compile(rb'\\w+')\n",
    "\n",
    "text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\"  # 타일 숫자로 1729를 담고있는 검색할 유니코드 텍스트\n",
    "            \" as 1729 = 1³ + 12³ = 9³ + 10³.\")        # 이 문자열은 컴파일 시 앞 문자열에 연결된다.\n",
    "\n",
    "text_bytes = text_str.encode('utf_8') # bytes 정규 표현식을 검색하기 위한 bytes 문자열\n",
    "\n",
    "print('Text', repr(text_str), sep='\\n  ')\n",
    "print('Numbers')\n",
    "print('  str  :', re_numbers_str.findall(text_str)) # str 패턴 r'\\d+'는 타밀과 아스키 숫자에 매칭\n",
    "print('  bytes:', re_numbers_bytes.findall(text_bytes)) # bytes 패턴 rb'\\d+'는 아스키 숫자에만 매칭\n",
    "print('Words')\n",
    "print('  str  :', re_words_str.findall(text_str)) # str패턴 r'\\w+'는 문자, 위첨자, 타밀, 아스키 숫자에 매칭\n",
    "print('  bytes:', re_words_bytes.findall(text_bytes)) # bytes패턴 rb'\\w+'는 문자와 숫자에 대한 아스키 바이트에만 매칭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9.2 os 모듈 함수에서 str과 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits-of-𝝅.txt\n",
      "b'digits-of-\\xf0\\x9d\\x9d\\x85.txt'\n"
     ]
    }
   ],
   "source": [
    "# 예제 2-23 str과 bytes를 인수로 호출한 listdir()메서드의 결과\n",
    "import os\n",
    "\n",
    "print(os.listdir('.')[-1])\n",
    "print(os.listdir(b'.')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.listdir(b'.')에서는 os.listdir('.')에서 나왔던 파일의 문자를 UTF-8로 인코딩 한 값으로 바꾼다 (파이가 바뀌었다)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
